---

title: Joint Entropies


keywords: fastai
sidebar: home_sidebar

summary: "Computing joint entropies exactly or by using importance sampling"
description: "Computing joint entropies exactly or by using importance sampling"
nb_path: "02_joint_entropy_computation.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 02_joint_entropy_computation.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This module helps compute joint entropies for dependent categorical variables given via a density $p((y_i)_i|w))$ in the Bayesian setting. We compute the density $p((y_i)_i)$ by marginalizing over $w$.</p>
<p>Two cases are implemented:</p>
<ul>
<li>exact joint entropies (which works for up 5 to joint variables depending on memory and # of classes);</li>
<li>estimated joint entropies using importance sampling of configurations.</li>
</ul>
<p>Note: "exact" based on the given draws of $w$. They are still an approximation because we do not integrate over $w$ but use Monte-Carlo samples.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Number of inference samples <code>K</code>:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">K</span> <span class="o">=</span> <span class="mi">20</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">toma</span> <span class="kn">import</span> <span class="n">toma</span>
<span class="kn">from</span> <span class="nn">tqdm.auto</span> <span class="kn">import</span> <span class="n">tqdm</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To run tests, we need a few sampled distributions.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>


<span class="k">def</span> <span class="nf">get_mixture_prob_dist</span><span class="p">(</span><span class="n">p1</span><span class="p">,</span> <span class="n">p2</span><span class="p">,</span> <span class="n">m</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">p1</span><span class="p">)</span> <span class="o">+</span> <span class="n">m</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">p2</span><span class="p">)</span>


<span class="n">p1</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]</span>
<span class="n">p2</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">]</span>
<span class="n">y1_ws</span> <span class="o">=</span> <span class="p">[</span><span class="n">get_mixture_prob_dist</span><span class="p">(</span><span class="n">p1</span><span class="p">,</span> <span class="n">p2</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">K</span><span class="p">)]</span>

<span class="n">p1</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">]</span>
<span class="n">p2</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]</span>
<span class="n">y2_ws</span> <span class="o">=</span> <span class="p">[</span><span class="n">get_mixture_prob_dist</span><span class="p">(</span><span class="n">p1</span><span class="p">,</span> <span class="n">p2</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">K</span><span class="p">)]</span>


<span class="k">def</span> <span class="nf">nested_to_tensor</span><span class="p">(</span><span class="o">*</span><span class="n">l</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">,</span> <span class="n">l</span><span class="p">)))</span>


<span class="n">ys_ws</span> <span class="o">=</span> <span class="n">nested_to_tensor</span><span class="p">(</span><span class="n">y1_ws</span><span class="p">,</span> <span class="n">y2_ws</span><span class="p">,</span> <span class="n">y1_ws</span><span class="p">,</span> <span class="n">y2_ws</span><span class="p">,</span> <span class="n">y1_ws</span><span class="p">,</span> <span class="n">y2_ws</span><span class="p">,</span> <span class="n">y1_ws</span><span class="p">,</span> <span class="n">y2_ws</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="JointEntropy-interface">JointEntropy interface<a class="anchor-link" href="#JointEntropy-interface"> </a></h1><p>Before we look at any implementations, we want to define an interface that we want to support.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="JointEntropy" class="doc_header"><code>class</code> <code>JointEntropy</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/joint_entropy.py#L15" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>JointEntropy</code>()</p>
</blockquote>
<p>Random variables (all with the same # of categories $C$) can be added via <a href="/batchbald_redux/joint_entropy_computation.html#JointEntropy.add_variables"><code>JointEntropy.add_variables</code></a>.</p>
<p><a href="/batchbald_redux/joint_entropy_computation.html#JointEntropy.compute"><code>JointEntropy.compute</code></a> computes the joint entropy.</p>
<p><a href="/batchbald_redux/joint_entropy_computation.html#JointEntropy.compute_batch"><code>JointEntropy.compute_batch</code></a> computes the joint entropy of the added variables with each of the variables in the provided batch probabilities in turn.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="JointEntropy.add_variables" class="doc_header"><code>JointEntropy.add_variables</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/joint_entropy.py#L26" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>JointEntropy.add_variables</code>(<strong><code>log_probs_N_K_C</code></strong>:<code>Tensor</code>)</p>
</blockquote>
<p>Expands the joint entropy to include more terms.</p>

</div>

</div>

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="JointEntropy.compute" class="doc_header"><code>JointEntropy.compute</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/joint_entropy.py#L22" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>JointEntropy.compute</code>()</p>
</blockquote>
<p>Computes the entropy of this joint entropy.</p>

</div>

</div>

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="JointEntropy.compute_batch" class="doc_header"><code>JointEntropy.compute_batch</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/joint_entropy.py#L30" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>JointEntropy.compute_batch</code>(<strong><code>log_probs_B_K_C</code></strong>:<code>Tensor</code>, <strong><code>output_entropies_B</code></strong>=<em><code>None</code></em>)</p>
</blockquote>
<p>Computes the joint entropy of the added variables together with the batch (one by one).</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Exact-Joint-Entropies">Exact Joint Entropies<a class="anchor-link" href="#Exact-Joint-Entropies"> </a></h2><p>To compute exact joint entropies, we have to compute all possible configurations of the $y_i$ and evaluate $p(y_1, \dots, y_n)$ by averaging over $p(y_1, \dots, y_n|w)$.</p>
<p>The number of samples $M=C^N$, where $N$ is the number of variables in the joint and $C$ is the number of classes.</p>
<p>For this, we provide a class <a href="/batchbald_redux/joint_entropy_computation.html#ExactJointEntropy"><code>ExactJointEntropy</code></a> that takes $K$ and starts with no variables in the joint.</p>
<h3 id="In-the-Paper">In the Paper<a class="anchor-link" href="#In-the-Paper"> </a></h3><p><img src="/batchbald_redux/batchbald_exact_joint_entropy.png" alt="Version in the paper"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Implementation">Implementation<a class="anchor-link" href="#Implementation"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="ExactJointEntropy" class="doc_header"><code>class</code> <code>ExactJointEntropy</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/joint_entropy.py#L37" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>ExactJointEntropy</code>(<strong><code>joint_probs_M_K</code></strong>:<code>Tensor</code>) :: <a href="/batchbald_redux/joint_entropy_computation.html#JointEntropy"><code>JointEntropy</code></a></p>
</blockquote>
<p>Random variables (all with the same # of categories $C$) can be added via <a href="/batchbald_redux/joint_entropy_computation.html#JointEntropy.add_variables"><code>JointEntropy.add_variables</code></a>.</p>
<p><a href="/batchbald_redux/joint_entropy_computation.html#JointEntropy.compute"><code>JointEntropy.compute</code></a> computes the joint entropy.</p>
<p><a href="/batchbald_redux/joint_entropy_computation.html#JointEntropy.compute_batch"><code>JointEntropy.compute_batch</code></a> computes the joint entropy of the added variables with each of the variables in the provided batch probabilities in turn.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">ExactJointEntropy</span><span class="p">(</span><span class="n">JointEntropy</span><span class="p">):</span>
    <span class="n">joint_probs_M_K</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">joint_probs_M_K</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">joint_probs_M_K</span> <span class="o">=</span> <span class="n">joint_probs_M_K</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">empty</span><span class="p">(</span><span class="n">K</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;ExactJointEntropy&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">ExactJointEntropy</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">K</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">probs_M</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">joint_probs_M_K</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">nats_M</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">probs_M</span><span class="p">)</span> <span class="o">*</span> <span class="n">probs_M</span>
        <span class="n">entropy</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">nats_M</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">entropy</span>

    <span class="k">def</span> <span class="nf">add_variables</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">log_probs_N_K_C</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;ExactJointEntropy&quot;</span><span class="p">:</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">joint_probs_M_K</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">log_probs_N_K_C</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="n">N</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">C</span> <span class="o">=</span> <span class="n">log_probs_N_K_C</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">joint_probs_K_M_1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">joint_probs_M_K</span><span class="o">.</span><span class="n">t</span><span class="p">()[:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">]</span>

        <span class="n">probs_N_K_C</span> <span class="o">=</span> <span class="n">log_probs_N_K_C</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span>

        <span class="c1"># Using lots of memory.</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
            <span class="n">probs_i__K_1_C</span> <span class="o">=</span> <span class="n">probs_N_K_C</span><span class="p">[</span><span class="n">i</span><span class="p">][:,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">joint_probs_K_M_1</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">joint_probs_K_M_C</span> <span class="o">=</span> <span class="n">joint_probs_K_M_1</span> <span class="o">*</span> <span class="n">probs_i__K_1_C</span>
            <span class="n">joint_probs_K_M_1</span> <span class="o">=</span> <span class="n">joint_probs_K_M_C</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">K</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">joint_probs_M_K</span> <span class="o">=</span> <span class="n">joint_probs_K_M_1</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">t</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">compute_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">log_probs_B_K_C</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">output_entropies_B</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">joint_probs_M_K</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">log_probs_B_K_C</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="n">B</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">C</span> <span class="o">=</span> <span class="n">log_probs_B_K_C</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">M</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">joint_probs_M_K</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">output_entropies_B</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">output_entropies_B</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">log_probs_B_K_C</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">log_probs_B_K_C</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="n">pbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">total</span><span class="o">=</span><span class="n">B</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;ExactJointEntropy.compute_batch&quot;</span><span class="p">,</span> <span class="n">leave</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="nd">@toma</span><span class="o">.</span><span class="n">execute</span><span class="o">.</span><span class="n">chunked</span><span class="p">(</span><span class="n">log_probs_B_K_C</span><span class="p">,</span> <span class="n">initial_step</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">dimension</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">def</span> <span class="nf">chunked_joint_entropy</span><span class="p">(</span><span class="n">chunked_log_probs_b_K_C</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">start</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">end</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">chunked_probs_b_K_C</span> <span class="o">=</span> <span class="n">chunked_log_probs_b_K_C</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span>
            <span class="n">b</span> <span class="o">=</span> <span class="n">chunked_probs_b_K_C</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

            <span class="n">probs_b_M_C</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
                <span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">C</span><span class="p">),</span>
                <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">joint_probs_M_K</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">joint_probs_M_K</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">b</span><span class="p">):</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">joint_probs_M_K</span><span class="p">,</span>
                    <span class="n">chunked_probs_b_K_C</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">joint_probs_M_K</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                    <span class="n">out</span><span class="o">=</span><span class="n">probs_b_M_C</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                <span class="p">)</span>
            <span class="n">probs_b_M_C</span> <span class="o">/=</span> <span class="n">K</span>

            <span class="n">output_entropies_B</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">]</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">probs_b_M_C</span><span class="p">)</span> <span class="o">*</span> <span class="n">probs_b_M_C</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span>
                <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">pbar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span>

        <span class="n">pbar</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">output_entropies_B</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="ExactJointEntropy.empty" class="doc_header"><code>ExactJointEntropy.empty</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/joint_entropy.py#L43" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>ExactJointEntropy.empty</code>(<strong><code>K</code></strong>:<code>int</code>, <strong><code>device</code></strong>=<em><code>None</code></em>, <strong><code>dtype</code></strong>=<em><code>None</code></em>)</p>
</blockquote>

</div>

</div>

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="ExactJointEntropy.add_variables" class="doc_header"><code>ExactJointEntropy.add_variables</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/joint_entropy.py#L53" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>ExactJointEntropy.add_variables</code>(<strong><code>log_probs_N_K_C</code></strong>:<code>Tensor</code>)</p>
</blockquote>
<p>Expands the joint entropy to include more terms.</p>

</div>

</div>

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="ExactJointEntropy.compute" class="doc_header"><code>ExactJointEntropy.compute</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/joint_entropy.py#L47" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>ExactJointEntropy.compute</code>()</p>
</blockquote>
<p>Computes the entropy of this joint entropy.</p>

</div>

</div>

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="ExactJointEntropy.compute_batch" class="doc_header"><code>ExactJointEntropy.compute_batch</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/joint_entropy.py#L70" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>ExactJointEntropy.compute_batch</code>(<strong><code>log_probs_B_K_C</code></strong>:<code>Tensor</code>, <strong><code>output_entropies_B</code></strong>=<em><code>None</code></em>)</p>
</blockquote>
<p>Computes the joint entropy of the added variables together with the batch (one by one).</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Examples">Examples<a class="anchor-link" href="#Examples"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">joint_entropy</span> <span class="o">=</span> <span class="n">ExactJointEntropy</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">double</span><span class="p">)</span>
<span class="n">entropy</span> <span class="o">=</span> <span class="n">joint_entropy</span><span class="o">.</span><span class="n">add_variables</span><span class="p">(</span><span class="n">ys_ws</span><span class="p">[:</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">log</span><span class="p">())</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">entropy</span><span class="p">,</span> <span class="mf">4.6479</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">entropy</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor(4.6479, dtype=torch.float64)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">joint_entropy</span> <span class="o">=</span> <span class="n">ExactJointEntropy</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
<span class="n">entropy</span> <span class="o">=</span> <span class="n">joint_entropy</span><span class="o">.</span><span class="n">add_variables</span><span class="p">(</span><span class="n">ys_ws</span><span class="p">[:</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">log</span><span class="p">())</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>
<span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">entropy</span><span class="p">,</span> <span class="mf">4.6479</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">entropy</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor(4.6479)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">joint_entropy</span> <span class="o">=</span> <span class="n">ExactJointEntropy</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
<span class="n">entropies</span> <span class="o">=</span> <span class="n">joint_entropy</span><span class="o">.</span><span class="n">add_variables</span><span class="p">(</span><span class="n">ys_ws</span><span class="p">[:</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">log</span><span class="p">())</span><span class="o">.</span><span class="n">compute_batch</span><span class="p">(</span><span class="n">ys_ws</span><span class="o">.</span><span class="n">log</span><span class="p">())</span>
<span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">entropies</span><span class="p">,</span> <span class="p">[</span><span class="mf">5.9735</span><span class="p">,</span> <span class="mf">5.6362</span><span class="p">,</span> <span class="mf">5.9735</span><span class="p">,</span> <span class="mf">5.6362</span><span class="p">,</span> <span class="mf">5.9735</span><span class="p">,</span> <span class="mf">5.6362</span><span class="p">,</span> <span class="mf">5.9735</span><span class="p">,</span> <span class="mf">5.6362</span><span class="p">])</span>
<span class="n">entropies</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>                                                                              </pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>tensor([5.9735, 5.6362, 5.9735, 5.6362, 5.9735, 5.6362, 5.9735, 5.6362],
       dtype=torch.float64)</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Sampled-Joint-Entropies">Sampled Joint Entropies<a class="anchor-link" href="#Sampled-Joint-Entropies"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To compute approximate joint entropies, we have to sample possible configurations of the $y_i$ from $p(y_1, \dots, y_n|w)$ stratified by $p(w)$ and evaluate $p(y_1, \dots, y_n)$ by averaging over $p(y_1, \dots, y_n|w)$.</p>
<p>The number of samples is $M$, so we use $\frac{M}{K}$ samples per $w$.</p>
<p>For this, we provide a class <a href="/batchbald_redux/joint_entropy_computation.html#SampledJointEntropy"><code>SampledJointEntropy</code></a> that takes $K$ and $M$, and implements the 'JointEntropy' interface.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To sample, we need a few helper functions.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="batch_multi_choices" class="doc_header"><code>batch_multi_choices</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/joint_entropy.py#L111" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>batch_multi_choices</code>(<strong><code>probs_b_C</code></strong>, <strong><code>M</code></strong>:<code>int</code>)</p>
</blockquote>
<p>probs_b_C: Ni... x C</p>
<p>Returns:
    choices: Ni... x M</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="gather_expand" class="doc_header"><code>gather_expand</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/joint_entropy.py#L127" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>gather_expand</code>(<strong><code>data</code></strong>, <strong><code>dim</code></strong>, <strong><code>index</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">batch_multi_choices</span><span class="p">(</span><span class="n">probs_b_C</span><span class="p">,</span> <span class="n">M</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    probs_b_C: Ni... x C</span>

<span class="sd">    Returns:</span>
<span class="sd">        choices: Ni... x M</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">probs_B_C</span> <span class="o">=</span> <span class="n">probs_b_C</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">probs_b_C</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>

    <span class="c1"># samples: Ni... x draw_per_xx</span>
    <span class="n">choices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">multinomial</span><span class="p">(</span><span class="n">probs_B_C</span><span class="p">,</span> <span class="n">num_samples</span><span class="o">=</span><span class="n">M</span><span class="p">,</span> <span class="n">replacement</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">choices_b_M</span> <span class="o">=</span> <span class="n">choices</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">probs_b_C</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">+</span> <span class="p">[</span><span class="n">M</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">choices_b_M</span>


<span class="k">def</span> <span class="nf">gather_expand</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">gather_expand</span><span class="o">.</span><span class="n">DEBUG_CHECKS</span><span class="p">:</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">index</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span><span class="n">dr</span> <span class="o">==</span> <span class="n">ir</span> <span class="ow">or</span> <span class="mi">1</span> <span class="ow">in</span> <span class="p">(</span><span class="n">dr</span><span class="p">,</span> <span class="n">ir</span><span class="p">)</span> <span class="k">for</span> <span class="n">dr</span><span class="p">,</span> <span class="n">ir</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">index</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>

    <span class="n">max_shape</span> <span class="o">=</span> <span class="p">[</span><span class="nb">max</span><span class="p">(</span><span class="n">dr</span><span class="p">,</span> <span class="n">ir</span><span class="p">)</span> <span class="k">for</span> <span class="n">dr</span><span class="p">,</span> <span class="n">ir</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">index</span><span class="o">.</span><span class="n">shape</span><span class="p">)]</span>
    <span class="n">new_data_shape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">max_shape</span><span class="p">)</span>
    <span class="n">new_data_shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span>

    <span class="n">new_index_shape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">max_shape</span><span class="p">)</span>
    <span class="n">new_index_shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">=</span> <span class="n">index</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span>

    <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">new_data_shape</span><span class="p">)</span>
    <span class="n">index</span> <span class="o">=</span> <span class="n">index</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">new_index_shape</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">dim</span><span class="p">,</span> <span class="n">index</span><span class="p">)</span>


<span class="n">gather_expand</span><span class="o">.</span><span class="n">DEBUG_CHECKS</span> <span class="o">=</span> <span class="kc">False</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="In-the-Paper">In the Paper<a class="anchor-link" href="#In-the-Paper"> </a></h3><p><img src="/batchbald_redux/batchbald_importance_sampling.png" alt="Version in the paper"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Implementation">Implementation<a class="anchor-link" href="#Implementation"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="SampledJointEntropy" class="doc_header"><code>class</code> <code>SampledJointEntropy</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/joint_entropy.py#L150" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>SampledJointEntropy</code>(<strong><code>sampled_joint_probs_M_K</code></strong>:<code>Tensor</code>) :: <a href="/batchbald_redux/joint_entropy_computation.html#JointEntropy"><code>JointEntropy</code></a></p>
</blockquote>
<p>Random variables (all with the same # of categories $C$) can be added via <a href="/batchbald_redux/joint_entropy_computation.html#SampledJointEntropy.add_variables"><code>SampledJointEntropy.add_variables</code></a>.</p>
<p><a href="/batchbald_redux/joint_entropy_computation.html#SampledJointEntropy.compute"><code>SampledJointEntropy.compute</code></a> computes the joint entropy.</p>
<p><a href="/batchbald_redux/joint_entropy_computation.html#SampledJointEntropy.compute_batch"><code>SampledJointEntropy.compute_batch</code></a> computes the joint entropy of the added variables with each of the variables in the provided batch probabilities in turn.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">SampledJointEntropy</span><span class="p">(</span><span class="n">JointEntropy</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Random variables (all with the same # of categories $C$) can be added via `SampledJointEntropy.add_variables`.</span>

<span class="sd">    `SampledJointEntropy.compute` computes the joint entropy.</span>

<span class="sd">    `SampledJointEntropy.compute_batch` computes the joint entropy of the added variables with each of the variables in the provided batch probabilities in turn.&quot;&quot;&quot;</span>

    <span class="n">sampled_joint_probs_M_K</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sampled_joint_probs_M_K</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sampled_joint_probs_M_K</span> <span class="o">=</span> <span class="n">sampled_joint_probs_M_K</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">empty</span><span class="p">(</span><span class="n">K</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;SampledJointEntropy&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">SampledJointEntropy</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">K</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">))</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">sample</span><span class="p">(</span><span class="n">probs_N_K_C</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">M</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;SampledJointEntropy&quot;</span><span class="p">:</span>
        <span class="n">K</span> <span class="o">=</span> <span class="n">probs_N_K_C</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="c1"># S: num of samples per w</span>
        <span class="n">S</span> <span class="o">=</span> <span class="n">M</span> <span class="o">//</span> <span class="n">K</span>

        <span class="n">choices_N_K_S</span> <span class="o">=</span> <span class="n">batch_multi_choices</span><span class="p">(</span><span class="n">probs_N_K_C</span><span class="p">,</span> <span class="n">S</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>

        <span class="n">expanded_choices_N_1_K_S</span> <span class="o">=</span> <span class="n">choices_N_K_S</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>
        <span class="n">expanded_probs_N_K_1_C</span> <span class="o">=</span> <span class="n">probs_N_K_C</span><span class="p">[:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>

        <span class="n">probs_N_K_K_S</span> <span class="o">=</span> <span class="n">gather_expand</span><span class="p">(</span><span class="n">expanded_probs_N_K_1_C</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">expanded_choices_N_1_K_S</span><span class="p">)</span>
        <span class="c1"># exp sum log seems necessary to avoid 0s?</span>
        <span class="n">probs_K_K_S</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">probs_N_K_K_S</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
        <span class="n">samples_K_M</span> <span class="o">=</span> <span class="n">probs_K_K_S</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">K</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>

        <span class="n">samples_M_K</span> <span class="o">=</span> <span class="n">samples_K_M</span><span class="o">.</span><span class="n">t</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">SampledJointEntropy</span><span class="p">(</span><span class="n">samples_M_K</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">sampled_joint_probs_M</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sampled_joint_probs_M_K</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">nats_M</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">sampled_joint_probs_M</span><span class="p">)</span>
        <span class="n">entropy</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">nats_M</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">entropy</span>

    <span class="k">def</span> <span class="nf">add_variables</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">log_probs_N_K_C</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">M2</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;SampledJointEntropy&quot;</span><span class="p">:</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">sampled_joint_probs_M_K</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">log_probs_N_K_C</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="n">sample_K_M1_1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sampled_joint_probs_M_K</span><span class="o">.</span><span class="n">t</span><span class="p">()[:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">]</span>

        <span class="n">new_sample_M2_K</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">log_probs_N_K_C</span><span class="o">.</span><span class="n">exp</span><span class="p">(),</span> <span class="n">M2</span><span class="p">)</span><span class="o">.</span><span class="n">sampled_joint_probs_M_K</span>
        <span class="n">new_sample_K_1_M2</span> <span class="o">=</span> <span class="n">new_sample_M2_K</span><span class="o">.</span><span class="n">t</span><span class="p">()[:,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>

        <span class="n">merged_sample_K_M1_M2</span> <span class="o">=</span> <span class="n">sample_K_M1_1</span> <span class="o">*</span> <span class="n">new_sample_K_1_M2</span>
        <span class="n">merged_sample_K_M</span> <span class="o">=</span> <span class="n">merged_sample_K_M1_M2</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">K</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">sampled_joint_probs_M_K</span> <span class="o">=</span> <span class="n">merged_sample_K_M</span><span class="o">.</span><span class="n">t</span><span class="p">()</span>

        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">compute_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">log_probs_B_K_C</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">output_entropies_B</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">sampled_joint_probs_M_K</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">log_probs_B_K_C</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="n">B</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">C</span> <span class="o">=</span> <span class="n">log_probs_B_K_C</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">M</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sampled_joint_probs_M_K</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">output_entropies_B</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">output_entropies_B</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">log_probs_B_K_C</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">log_probs_B_K_C</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="n">pbar</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">total</span><span class="o">=</span><span class="n">B</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;SampledJointEntropy.compute_batch&quot;</span><span class="p">,</span> <span class="n">leave</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="nd">@toma</span><span class="o">.</span><span class="n">execute</span><span class="o">.</span><span class="n">chunked</span><span class="p">(</span><span class="n">log_probs_B_K_C</span><span class="p">,</span> <span class="n">initial_step</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">dimension</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">def</span> <span class="nf">chunked_joint_entropy</span><span class="p">(</span><span class="n">chunked_log_probs_b_K_C</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">start</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">end</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">b</span> <span class="o">=</span> <span class="n">chunked_log_probs_b_K_C</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

            <span class="n">probs_b_M_C</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span>
                <span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">C</span><span class="p">),</span>
                <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sampled_joint_probs_M_K</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sampled_joint_probs_M_K</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">b</span><span class="p">):</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">sampled_joint_probs_M_K</span><span class="p">,</span>
                    <span class="n">chunked_log_probs_b_K_C</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sampled_joint_probs_M_K</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">exp</span><span class="p">(),</span>
                    <span class="n">out</span><span class="o">=</span><span class="n">probs_b_M_C</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                <span class="p">)</span>
            <span class="n">probs_b_M_C</span> <span class="o">/=</span> <span class="n">K</span>

            <span class="n">q_1_M_1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sampled_joint_probs_M_K</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="kc">None</span><span class="p">]</span>

            <span class="n">output_entropies_B</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">]</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">probs_b_M_C</span><span class="p">)</span> <span class="o">*</span> <span class="n">probs_b_M_C</span> <span class="o">/</span> <span class="n">q_1_M_1</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span> <span class="o">/</span> <span class="n">M</span><span class="p">,</span>
                <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="n">pbar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span>

        <span class="n">pbar</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">output_entropies_B</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="SampledJointEntropy.empty" class="doc_header"><code>SampledJointEntropy.empty</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/joint_entropy.py#L162" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>SampledJointEntropy.empty</code>(<strong><code>K</code></strong>:<code>int</code>, <strong><code>device</code></strong>=<em><code>None</code></em>, <strong><code>dtype</code></strong>=<em><code>None</code></em>)</p>
</blockquote>

</div>

</div>

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="SampledJointEntropy.sample" class="doc_header"><code>SampledJointEntropy.sample</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/joint_entropy.py#L166" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>SampledJointEntropy.sample</code>(<strong><code>probs_N_K_C</code></strong>:<code>Tensor</code>, <strong><code>M</code></strong>:<code>int</code>)</p>
</blockquote>

</div>

</div>

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="SampledJointEntropy.compute" class="doc_header"><code>SampledJointEntropy.compute</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/joint_entropy.py#L186" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>SampledJointEntropy.compute</code>()</p>
</blockquote>
<p>Computes the entropy of this joint entropy.</p>

</div>

</div>

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="SampledJointEntropy.add_variables" class="doc_header"><code>SampledJointEntropy.add_variables</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/joint_entropy.py#L192" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>SampledJointEntropy.add_variables</code>(<strong><code>log_probs_N_K_C</code></strong>:<code>Tensor</code>, <strong><code>M2</code></strong>:<code>int</code>)</p>
</blockquote>
<p>Expands the joint entropy to include more terms.</p>

</div>

</div>

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="SampledJointEntropy.compute_batch" class="doc_header"><code>SampledJointEntropy.compute_batch</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/joint_entropy.py#L207" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>SampledJointEntropy.compute_batch</code>(<strong><code>log_probs_B_K_C</code></strong>:<code>Tensor</code>, <strong><code>output_entropies_B</code></strong>=<em><code>None</code></em>)</p>
</blockquote>
<p>Computes the joint entropy of the added variables together with the batch (one by one).</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Examples">Examples<a class="anchor-link" href="#Examples"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">joint_entropy</span> <span class="o">=</span> <span class="n">SampledJointEntropy</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">double</span><span class="p">)</span>
<span class="n">entropy</span> <span class="o">=</span> <span class="n">joint_entropy</span><span class="o">.</span><span class="n">add_variables</span><span class="p">(</span><span class="n">ys_ws</span><span class="p">[:</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">log</span><span class="p">(),</span> <span class="mi">100000</span><span class="p">)</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="n">entropy</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">entropy</span><span class="p">,</span> <span class="mf">4.6479</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>tensor(4.6472, dtype=torch.float64)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">joint_entropy</span> <span class="o">=</span> <span class="n">SampledJointEntropy</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">double</span><span class="p">)</span>
<span class="n">entropy</span> <span class="o">=</span> <span class="n">joint_entropy</span><span class="o">.</span><span class="n">add_variables</span><span class="p">(</span><span class="n">ys_ws</span><span class="p">[:</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">log</span><span class="p">(),</span> <span class="mi">100000</span><span class="p">)</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="n">entropy</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">entropy</span><span class="p">,</span> <span class="mf">4.6479</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>tensor(4.6458, dtype=torch.float64)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">joint_entropy</span> <span class="o">=</span> <span class="n">SampledJointEntropy</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span>
<span class="n">entropies</span> <span class="o">=</span> <span class="n">joint_entropy</span><span class="o">.</span><span class="n">add_variables</span><span class="p">(</span><span class="n">ys_ws</span><span class="p">[:</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">log</span><span class="p">(),</span> <span class="mi">10000</span><span class="p">)</span><span class="o">.</span><span class="n">compute_batch</span><span class="p">(</span><span class="n">ys_ws</span><span class="o">.</span><span class="n">log</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="n">entropies</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span>
    <span class="n">entropies</span><span class="p">,</span>
    <span class="p">[</span><span class="mf">5.9735</span><span class="p">,</span> <span class="mf">5.6362</span><span class="p">,</span> <span class="mf">5.9735</span><span class="p">,</span> <span class="mf">5.6362</span><span class="p">,</span> <span class="mf">5.9735</span><span class="p">,</span> <span class="mf">5.6362</span><span class="p">,</span> <span class="mf">5.9735</span><span class="p">,</span> <span class="mf">5.6362</span><span class="p">],</span>
    <span class="n">atol</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>


SampledJointEntropy.compute_batch:   0%|          | 0/8 [00:00&lt;?, ?it/s]</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">RuntimeError</span>                              Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-45-b24b357fb3de&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-intense-fg ansi-bold">      1</span> joint_entropy <span class="ansi-blue-fg">=</span> SampledJointEntropy<span class="ansi-blue-fg">.</span>empty<span class="ansi-blue-fg">(</span>K<span class="ansi-blue-fg">,</span> dtype<span class="ansi-blue-fg">=</span>torch<span class="ansi-blue-fg">.</span>float<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">----&gt; 2</span><span class="ansi-red-fg"> </span>entropies <span class="ansi-blue-fg">=</span> joint_entropy<span class="ansi-blue-fg">.</span>add_variables<span class="ansi-blue-fg">(</span>ys_ws<span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">:</span><span class="ansi-cyan-fg">4</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">.</span>log<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span> <span class="ansi-cyan-fg">10000</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">.</span>compute_batch<span class="ansi-blue-fg">(</span>ys_ws<span class="ansi-blue-fg">.</span>log<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">      3</span> 
<span class="ansi-green-intense-fg ansi-bold">      4</span> print<span class="ansi-blue-fg">(</span>entropies<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">      5</span> assert np.allclose(

<span class="ansi-green-fg">&lt;ipython-input-43-ae113234e04b&gt;</span> in <span class="ansi-cyan-fg">compute_batch</span><span class="ansi-blue-fg">(self, log_probs_B_K_C, output_entropies_B)</span>
<span class="ansi-green-intense-fg ansi-bold">     72</span>         <span class="ansi-blue-fg">@</span>toma<span class="ansi-blue-fg">.</span>execute<span class="ansi-blue-fg">.</span>chunked<span class="ansi-blue-fg">(</span>log_probs_B_K_C<span class="ansi-blue-fg">,</span> initial_step<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">1024</span><span class="ansi-blue-fg">,</span> dimension<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     73</span>         <span class="ansi-blue-fg">@</span>torch<span class="ansi-blue-fg">.</span>jit<span class="ansi-blue-fg">.</span>script
<span class="ansi-green-fg">---&gt; 74</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">def</span> chunked_joint_entropy<span class="ansi-blue-fg">(</span>chunked_log_probs_b_K_C<span class="ansi-blue-fg">:</span> torch<span class="ansi-blue-fg">.</span>Tensor<span class="ansi-blue-fg">,</span> start<span class="ansi-blue-fg">:</span> int<span class="ansi-blue-fg">,</span> end<span class="ansi-blue-fg">:</span> int<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">     75</span>             M <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>sampled_joint_probs_M_K<span class="ansi-blue-fg">.</span>shape<span class="ansi-blue-fg">[</span><span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">]</span>
<span class="ansi-green-intense-fg ansi-bold">     76</span> 

<span class="ansi-green-fg">~/anaconda3/envs/active_learning/lib/python3.8/site-packages/torch/jit/_script.py</span> in <span class="ansi-cyan-fg">script</span><span class="ansi-blue-fg">(obj, optimize, _frames_up, _rcb)</span>
<span class="ansi-green-intense-fg ansi-bold">    937</span>         <span class="ansi-green-fg">if</span> _rcb <span class="ansi-green-fg">is</span> <span class="ansi-green-fg">None</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    938</span>             _rcb <span class="ansi-blue-fg">=</span> _jit_internal<span class="ansi-blue-fg">.</span>createResolutionCallbackFromClosure<span class="ansi-blue-fg">(</span>obj<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 939</span><span class="ansi-red-fg">         fn = torch._C._jit_script_compile(
</span><span class="ansi-green-intense-fg ansi-bold">    940</span>             qualified_name<span class="ansi-blue-fg">,</span> ast<span class="ansi-blue-fg">,</span> _rcb<span class="ansi-blue-fg">,</span> get_default_args<span class="ansi-blue-fg">(</span>obj<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    941</span>         )

<span class="ansi-red-fg">RuntimeError</span>: 
attribute lookup is not defined on python value of type &#39;SampledJointEntropy&#39;:
  File &#34;&lt;ipython-input-43-ae113234e04b&gt;&#34;, line 75
        @torch.jit.script
        def chunked_joint_entropy(chunked_log_probs_b_K_C: torch.Tensor, start: int, end: int):            
            M = self.sampled_joint_probs_M_K.shape[0]
                ~~~~~~~~~~~~~~~~~~~~~~~~~~~~ &lt;--- HERE
        
            b, K, C = chunked_log_probs_b_K_C.shape[0]
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Dynamically-chooses-JointEntropy-Method">Dynamically chooses JointEntropy Method<a class="anchor-link" href="#Dynamically-chooses-JointEntropy-Method"> </a></h2><p>Finally, we want to be able to dynamically pick either class depending on the maximum number of samples we want. (And also resample if necessary as we add variables.)</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="DynamicJointEntropy" class="doc_header"><code>class</code> <code>DynamicJointEntropy</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/joint_entropy.py#L251" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>DynamicJointEntropy</code>(<strong><code>M</code></strong>:<code>int</code>, <strong><code>max_N</code></strong>:<code>int</code>, <strong><code>K</code></strong>:<code>int</code>, <strong><code>C</code></strong>:<code>int</code>, <strong><code>dtype</code></strong>=<em><code>None</code></em>, <strong><code>device</code></strong>=<em><code>None</code></em>) :: <a href="/batchbald_redux/joint_entropy_computation.html#JointEntropy"><code>JointEntropy</code></a></p>
</blockquote>
<p>Random variables (all with the same # of categories $C$) can be added via <a href="/batchbald_redux/joint_entropy_computation.html#JointEntropy.add_variables"><code>JointEntropy.add_variables</code></a>.</p>
<p><a href="/batchbald_redux/joint_entropy_computation.html#JointEntropy.compute"><code>JointEntropy.compute</code></a> computes the joint entropy.</p>
<p><a href="/batchbald_redux/joint_entropy_computation.html#JointEntropy.compute_batch"><code>JointEntropy.compute_batch</code></a> computes the joint entropy of the added variables with each of the variables in the provided batch probabilities in turn.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">DynamicJointEntropy</span><span class="p">(</span><span class="n">JointEntropy</span><span class="p">):</span>
    <span class="n">inner</span><span class="p">:</span> <span class="n">JointEntropy</span>
    <span class="n">log_probs_max_N_K_C</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
    <span class="n">N</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">M</span><span class="p">:</span> <span class="nb">int</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">M</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">max_N</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">K</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">C</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">M</span> <span class="o">=</span> <span class="n">M</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">N</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_N</span> <span class="o">=</span> <span class="n">max_N</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">inner</span> <span class="o">=</span> <span class="n">ExactJointEntropy</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_probs_max_N_K_C</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">max_N</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">C</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">add_variables</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">log_probs_N_K_C</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="s2">&quot;DynamicJointEntropy&quot;</span><span class="p">:</span>
        <span class="n">C</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_probs_max_N_K_C</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
        <span class="n">add_N</span> <span class="o">=</span> <span class="n">log_probs_N_K_C</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_probs_max_N_K_C</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">N</span> <span class="o">+</span> <span class="n">add_N</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_probs_max_N_K_C</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">==</span> <span class="n">C</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">log_probs_max_N_K_C</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">N</span> <span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">N</span> <span class="o">+</span> <span class="n">add_N</span><span class="p">]</span> <span class="o">=</span> <span class="n">log_probs_N_K_C</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">N</span> <span class="o">+=</span> <span class="n">add_N</span>

        <span class="n">num_exact_samples</span> <span class="o">=</span> <span class="n">C</span> <span class="o">**</span> <span class="bp">self</span><span class="o">.</span><span class="n">N</span>
        <span class="k">if</span> <span class="n">num_exact_samples</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">M</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">inner</span> <span class="o">=</span> <span class="n">SampledJointEntropy</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_probs_max_N_K_C</span><span class="p">[:</span> <span class="bp">self</span><span class="o">.</span><span class="n">N</span><span class="p">]</span><span class="o">.</span><span class="n">exp</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">M</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">inner</span><span class="o">.</span><span class="n">add_variables</span><span class="p">(</span><span class="n">log_probs_N_K_C</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">inner</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">compute_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">log_probs_B_K_C</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">output_entropies_B</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Computes the joint entropy of the added variables together with the batch (one by one).&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">inner</span><span class="o">.</span><span class="n">compute_batch</span><span class="p">(</span><span class="n">log_probs_B_K_C</span><span class="p">,</span> <span class="n">output_entropies_B</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="DynamicJointEntropy.add_variables" class="doc_header"><code>DynamicJointEntropy.add_variables</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/joint_entropy.py#L265" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>DynamicJointEntropy.add_variables</code>(<strong><code>log_probs_N_K_C</code></strong>:<code>Tensor</code>)</p>
</blockquote>
<p>Expands the joint entropy to include more terms.</p>

</div>

</div>

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="DynamicJointEntropy.compute_batch" class="doc_header"><code>DynamicJointEntropy.compute_batch</code><a href="https://github.com/blackhc/batchbald_redux/tree/master/batchbald_redux/joint_entropy.py#L286" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>DynamicJointEntropy.compute_batch</code>(<strong><code>log_probs_B_K_C</code></strong>:<code>Tensor</code>, <strong><code>output_entropies_B</code></strong>=<em><code>None</code></em>)</p>
</blockquote>
<p>Computes the joint entropy of the added variables together with the batch (one by one).</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Examples">Examples<a class="anchor-link" href="#Examples"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">joint_entropy</span> <span class="o">=</span> <span class="n">DynamicJointEntropy</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">double</span><span class="p">)</span>
<span class="n">entropy</span> <span class="o">=</span> <span class="n">joint_entropy</span><span class="o">.</span><span class="n">add_variables</span><span class="p">(</span><span class="n">ys_ws</span><span class="p">[:</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">log</span><span class="p">())</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="n">entropy</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">entropy</span><span class="p">,</span> <span class="mf">4.6479</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>tensor(4.6479, dtype=torch.float64)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">assert</span> <span class="nb">type</span><span class="p">(</span><span class="n">joint_entropy</span><span class="o">.</span><span class="n">inner</span><span class="p">)</span> <span class="o">==</span> <span class="n">ExactJointEntropy</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">entropy</span> <span class="o">=</span> <span class="n">joint_entropy</span><span class="o">.</span><span class="n">add_variables</span><span class="p">(</span><span class="n">ys_ws</span><span class="p">[</span><span class="mi">4</span><span class="p">:]</span><span class="o">.</span><span class="n">log</span><span class="p">())</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="n">entropy</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span><span class="n">entropy</span><span class="p">,</span> <span class="mf">9.2756</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>tensor(9.1794, dtype=torch.float64)
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">assert</span> <span class="nb">type</span><span class="p">(</span><span class="n">joint_entropy</span><span class="o">.</span><span class="n">inner</span><span class="p">)</span> <span class="o">==</span> <span class="n">SampledJointEntropy</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

</div>
 

