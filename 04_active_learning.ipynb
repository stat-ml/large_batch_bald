{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp active_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appended /home/blackhc/PycharmProjects/blackhc.batchbald/src to paths\n",
      "Switched to directory /home/blackhc/PycharmProjects/blackhc.batchbald\n",
      "%load_ext autoreload\n",
      "%autoreload 2\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "import blackhc.project.script\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Learning\n",
    "> Everything needed for Active Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Active Learning Data\n",
    "\n",
    "For active learning, we need to split the available training data between a training set and a pool set of (unlabelled) data, which we score using our model and acquisition function and add to the training set peu a peu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "import collections\n",
    "from typing import Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "\n",
    "class ActiveLearningData:\n",
    "    \"\"\"Splits `dataset` into an active dataset and an available dataset.\"\"\"\n",
    "\n",
    "    dataset: data.Dataset\n",
    "    training_dataset: data.Dataset\n",
    "    pool_dataset: data.Dataset\n",
    "    training_mask: np.ndarray\n",
    "    pool_mask: np.ndarray\n",
    "\n",
    "    def __init__(self, dataset: data.Dataset):\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "        self.training_mask = np.full((len(dataset),), False) # filled with False\n",
    "        self.pool_mask = np.full((len(dataset),), True)\n",
    "\n",
    "        self.training_dataset = data.Subset(self.dataset, None) # subset with None indeces\n",
    "        self.pool_dataset = data.Subset(self.dataset, None)\n",
    "\n",
    "        self._update_indices()\n",
    "\n",
    "    def _update_indices(self):\n",
    "        self.training_dataset.indices = np.nonzero(self.training_mask)[0]\n",
    "        self.pool_dataset.indices = np.nonzero(self.pool_mask)[0]\n",
    "\n",
    "    def get_dataset_indices(self, pool_indices: List[int]) -> List[int]:\n",
    "        \"\"\"Transform indices (in `pool_dataset`) to indices in the original `dataset`.\"\"\"\n",
    "        indices = self.pool_dataset.indices[pool_indices]\n",
    "        return indices\n",
    "\n",
    "    def acquire(self, pool_indices):\n",
    "        \"\"\"Acquire elements from the pool dataset into the training dataset.\n",
    "\n",
    "        Add them to training dataset & remove them from the pool dataset.\"\"\"\n",
    "        indices = self.get_dataset_indices(pool_indices)\n",
    "\n",
    "        self.training_mask[indices] = True\n",
    "        self.pool_mask[indices] = False\n",
    "        self._update_indices()\n",
    "\n",
    "    def remove_from_pool(self, pool_indices):\n",
    "        indices = self.get_dataset_indices(pool_indices)\n",
    "\n",
    "        self.pool_mask[indices] = False\n",
    "        self._update_indices()\n",
    "\n",
    "    def get_random_pool_indices(self, size) -> torch.LongTensor:\n",
    "        assert 0 <= size <= len(self.pool_dataset)\n",
    "        pool_indices = torch.randperm(len(self.pool_dataset))[:size] # random permutation of integers\n",
    "        return pool_indices\n",
    "\n",
    "    def extract_dataset_from_pool(self, size) -> data.Dataset:\n",
    "        \"\"\"Extract a dataset randomly from the pool dataset and make those indices unavailable.\n",
    "\n",
    "        Useful for extracting a validation set.\"\"\"\n",
    "        return self.extract_dataset_from_pool_from_indices(self.get_random_pool_indices(size))\n",
    "\n",
    "    def extract_dataset_from_pool_from_indices(self, pool_indices) -> data.Dataset:\n",
    "        \"\"\"Extract a dataset from the pool dataset and make those indices unavailable.\n",
    "\n",
    "        Useful for extracting a validation set.\"\"\"\n",
    "        dataset_indices = self.get_dataset_indices(pool_indices)\n",
    "\n",
    "        self.remove_from_pool(pool_indices)\n",
    "        return data.Subset(self.dataset, dataset_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"ActiveLearningData.get_dataset_indices\" class=\"doc_header\"><code>ActiveLearningData.get_dataset_indices</code><a href=\"__main__.py#L27\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>ActiveLearningData.get_dataset_indices</code>(**`pool_indices`**:`List`\\[`int`\\])\n",
       "\n",
       "Transform indices (in `pool_dataset`) to indices in the original `dataset`."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"ActiveLearningData.acquire\" class=\"doc_header\"><code>ActiveLearningData.acquire</code><a href=\"__main__.py#L32\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>ActiveLearningData.acquire</code>(**`pool_indices`**)\n",
       "\n",
       "Acquire elements from the pool dataset into the training dataset.\n",
       "\n",
       "Add them to training dataset & remove them from the pool dataset."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"ActiveLearningData.remove_from_pool\" class=\"doc_header\"><code>ActiveLearningData.remove_from_pool</code><a href=\"__main__.py#L42\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>ActiveLearningData.remove_from_pool</code>(**`pool_indices`**)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"ActiveLearningData.get_random_pool_indices\" class=\"doc_header\"><code>ActiveLearningData.get_random_pool_indices</code><a href=\"__main__.py#L48\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>ActiveLearningData.get_random_pool_indices</code>(**`size`**)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"ActiveLearningData.extract_dataset_from_pool\" class=\"doc_header\"><code>ActiveLearningData.extract_dataset_from_pool</code><a href=\"__main__.py#L53\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>ActiveLearningData.extract_dataset_from_pool</code>(**`size`**)\n",
       "\n",
       "Extract a dataset randomly from the pool dataset and make those indices unavailable.\n",
       "\n",
       "Useful for extracting a validation set."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"ActiveLearningData.extract_dataset_from_pool_from_indices\" class=\"doc_header\"><code>ActiveLearningData.extract_dataset_from_pool_from_indices</code><a href=\"__main__.py#L60\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>ActiveLearningData.extract_dataset_from_pool_from_indices</code>(**`pool_indices`**)\n",
       "\n",
       "Extract a dataset from the pool dataset and make those indices unavailable.\n",
       "\n",
       "Useful for extracting a validation set."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(ActiveLearningData.get_dataset_indices)\n",
    "show_doc(ActiveLearningData.acquire)\n",
    "show_doc(ActiveLearningData.remove_from_pool)\n",
    "show_doc(ActiveLearningData.get_random_pool_indices)\n",
    "show_doc(ActiveLearningData.extract_dataset_from_pool)\n",
    "show_doc(ActiveLearningData.extract_dataset_from_pool_from_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "\n",
    "\n",
    "def get_balanced_sample_indices(target_classes: List, num_classes, n_per_digit=2) -> List[int]:\n",
    "    \"\"\"Given `target_classes` randomly sample `n_per_digit` for each of the `num_classes` classes.\"\"\"\n",
    "    permed_indices = torch.randperm(len(target_classes))\n",
    "\n",
    "    if n_per_digit == 0:\n",
    "        return []\n",
    "\n",
    "    num_samples_by_class = collections.defaultdict(int)\n",
    "    initial_samples = []\n",
    "\n",
    "    for i in range(len(permed_indices)):\n",
    "        permed_index = int(permed_indices[i])\n",
    "        index, target = permed_index, int(target_classes[permed_index])\n",
    "\n",
    "        num_target_samples = num_samples_by_class[target]\n",
    "        if num_target_samples == n_per_digit:\n",
    "            continue\n",
    "\n",
    "        initial_samples.append(index)\n",
    "        num_samples_by_class[target] += 1\n",
    "\n",
    "        if len(initial_samples) == num_classes * n_per_digit:\n",
    "            break\n",
    "\n",
    "    return initial_samples\n",
    "\n",
    "\n",
    "def get_subset_base_indices(dataset: data.Subset, indices: List[int]):\n",
    "    return [int(dataset.indices[index]) for index in indices]\n",
    "\n",
    "\n",
    "def get_base_indices(dataset: data.Dataset, indices: List[int]):\n",
    "    if isinstance(dataset, data.Subset):\n",
    "        return get_base_indices(dataset.dataset, get_subset_base_indices(dataset, indices))\n",
    "    return indices\n",
    "\n",
    "\n",
    "class RandomFixedLengthSampler(data.Sampler):\n",
    "    \"\"\"\n",
    "    Sometimes, you really want to do more with little data without increasing the number of epochs.\n",
    "\n",
    "    This sampler takes a `dataset` and draws `target_length` samples from it (with repetition).\n",
    "    \"\"\"\n",
    "\n",
    "    dataset: data.Dataset\n",
    "    target_length: int\n",
    "\n",
    "    def __init__(self, dataset: data.Dataset, target_length: int):\n",
    "        super().__init__(dataset)\n",
    "        self.dataset = dataset\n",
    "        self.target_length = target_length\n",
    "\n",
    "    def __iter__(self):\n",
    "        # Ensure that we don't lose data by accident.\n",
    "        if self.target_length < len(self.dataset):\n",
    "            return iter(torch.randperm(len(self.dataset)).tolist())\n",
    "\n",
    "        # Sample slightly more indices to avoid biasing towards start of dataset.\n",
    "        # Have the same number of duplicates for each sample.\n",
    "        indices = torch.randperm(\n",
    "            self.target_length + (-self.target_length % len(self.dataset))\n",
    "        )\n",
    "\n",
    "        return iter((indices[:self.target_length] % len(self.dataset)).tolist())\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
